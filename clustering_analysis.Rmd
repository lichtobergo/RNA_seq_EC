---
title: "Clustering EC RNA seq data"
output: html_notebook
---

We use die DESeq object generated in the DGE analysis script.

# Data pre-processing

```{r data mangling}

metaData <- samples %>% 
  dplyr::filter(
    condition %notin% c("OVA", "EAE")
  ) %>% 
  dplyr::select(
    sample_name,
    tissue
  )
# filter 5000 most variable genes
topVarGenes <- head(
  order(
    rowVars(
      counts(dds, normalized = TRUE)[ , metaData$sample_name]
    ),
    decreasing = T
  ),
  5000
)
# assign normalized counts to object
dat <- counts(dds, normalized = TRUE)[topVarGenes, metaData$sample_name]
# scale and center data
scaledata <- t(scale(t(dat)))

```


## Hierarchical clustering the expression data

```{r hierarchical clustering}

# cluster row by Pearson correlation
hr <- hclust(
  as.dist(
    1 - cor(t(scaledata), method = "pearson")
  ),
  method = "complete"
)
# cluster columns by spearman correlation
hc <- hclust(
  as.dist(
    1 - cor(scaledata, method = "spearman")
  ),
  method = "complete"
)

```


```{r clustering heatmap}

# visualize clusters with heatmap
pheatmap(
  mat = assay(vsd, normalized = T)[topVarGenes, metaData$sample_name],
  cluster_rows = hr,
  cluster_cols = hc,
  scale = "row",
  color = viridis::viridis(50),
  show_rownames = F,
  show_colnames = F,
  annotation_col = samples[ , c("tissue", "condition"), drop = F]
)
  

```

⌡
```{r}

TreeC <- as.dendrogram(hc, method = "average")
plot(
  TreeC,
  main = "Sample Clustering",
  ylab = "height"
)

TreeR <- as.dendrogram(hr, method = "average")
plot(
  TreeR,
  main = "Gene Clustering",
  ylab = "height"
)


```


```{r tree cutting}

hclust1.5 <- cutree(hr, h = 1.5)
hclust1.0 <- cutree(hr, h = 1.0)
hclust0.5 <- cutree(hr, h = 0.5)

head(hclust1.5)

```

```{r visualize cluster membership}

library(dendextend)
#plot tree
plot(
  TreeR,
  leaflab = "none",
  main = "Gene Clustering",
  ylab = "height"
)

#add the three cluster vectors
the_bars <- cbind(
  hclust0.5,
  hclust1.0,
  hclust1.5
)
# this makes the bar
colored_bars(
  the_bars,
  TreeR,
  sort_by_labels_order = T,
  y_shift = -0.1,
  rowLabels = c("h=0.5", "h=1.0", "h=1.5"),
  cex.rowLabels = 0.7
)
abline(h = 1.5, lty = 2, col = "grey")
abline(h = 1.0, lty = 2, col = "grey")
abline(h = 0.5, lty = 2, col = "grey")
# plot.new()

```


```{r}

# clustering defined number of clusters
hclust4 <- cutree(hr, k = 4)
plot(
  TreeR,
  leaflab = "none",
  main = "Gene Clustering",
  ylab = "Height"
)
colored_bars(
  hclust4,
  TreeR,
  sort_by_labels_order = T,
  y_shift = -0.1,
  rowLabels = c("k=4"),
  cex.rowLabels = 0.7
)
plot.new()

```


```{r dynamic tree cut}

library(dynamicTreeCut)
clusDyn <- cutreeDynamic(
  hr,
  distM = as.matrix(
    as.dist(
      1 - cor(
        t(scaledata)
      )
    )
  ),
  method = "hybrid"
)

plot(
  TreeR,
  leaflab = "none",
  main = "Gene Clustering",
  ylab = "Height"
)
colored_bars(
  clusDyn,
  TreeR,
  sort_by_labels_order = T,
  y_shift = -0.1, 
  rowLabels = c("Dynamic"),
  cex.rowLabels = 0.7
)
plot.new()

```


```{r}
# function to calculate the centers (medoids) of the clusters
clust.core <- function(i, dat, clusters) {
  ind <- (clusters == i)
  colMeans(dat[ind, ])
}

clusters <- hclust1.5
cores <- sapply(
  unique(clusters),
  clust.core,
  scaledata,
  clusters
)

```



```{r}
# plot cores of cluster as function of samples
## make dataframe of cores by tissue and condition
d <- data.frame(
  cbind(
    metaData$tissue,
    metaData$condition,
    cores
  )
)
colnames(d) <- c("tissue", paste0("clust_", 1:ncol(cores)))

## get dataframe in shape for plotting
dmolten <- reshape2::melt(d, id.var = c("tissue"))
dmolten <- dmolten[order(dmolten$tissue), ]

## make the plot
p1 <- ggplot(
  dmolten,
  aes(tissue, value, col = variable)
) +
  geom_point() +
  geom_line() +
  # scale_x_discrete(
  #   minor_breaks = NULL,
  #   breaks = c(as.numeric(levels(factor(dmolten$tissue))))
  # ) +
  xlab("Tissue") +
  ylab("Expression") +
  labs(
    title = "Cluster Core Expression by Tissue",
    color = "Cluster"
  )

p1

```

# K-means Clustering

## Filter the data
Filter the notoriously noisy RNA seq data
```{r filter data by var and mean}
# prepare data object
dat <- fpm(
  dds,
  robust = T
)
# mean/variance calculations
dat_var <- apply(dat, 1, var)
dat_mean <- apply(dat, 1, mean)
plot(
  log2(dat_mean),
  log2(dat_var),
  pch = '.'
)
abline(
  h = log2(50),
  col = "red"
)
abline(
  v = log2(50),
  col = "red"
)
dat <- dat[which(dat_mean > 50 & dat_var > 50), metaData$sample_name]
# scale the data
scaleData <- t(scale(t(dat)))

```

We can cluster the data to identify outliers
```{r HC outliers}

hc <- hclust(
  as.dist(
    1 - cor(scaleData, method = "spearman")
  ),
  method = "complete"
)
TreeC <- as.dendrogram(hc, method = "average")
plot(
  TreeC,
  main = "Sample Clustering",
  ylab = "Height"
)

```

# K-Means: How many clusters?

## SSE: sum of squared errors
```{r SSE k-evaluation}

wss <- (nrow(scaleData) - 1) * sum(apply(scaleData, 2, var))
for (i in 2:20) wss[i] <- sum(
  kmeans(
    scaleData,
    centers = i
  )$withinss
)
plot(
  1:20,
  wss,
  type = "b",
  xlab = "Number of Clusters",
  ylab = "Within groups sum of squares"
)


```
So by this measure the optimum is **4 clusters**


## Average silhouette width
The next method is by estimating the optimum number using the average silhouette width. The silhouette value describes how similar a gene is to its own cluster (cohesion) compared to other clusters (separation). A high value indicates that the gene is well placed. So if the average of all of these silhouettes is high then the number of clusters is good.

```{r avg silhouette width}

library(cluster)
sil <- rep(0, 20)
# repeat k-means for 1:20 and extract silhouette:
for(i in 2:20){
  k1to20 <- kmeans(
    scaleData,
    center = i,
    nstart = 25, 
    iter.max = 20
  )
  ss <- silhouette(
    k1to20$cluster, 
    dist(scaleData)
  )
  sil[i] <- mean(ss[ , 3])
}

# Plot the average silhoutte width
plot(
  1:20,
  sil,
  type = "b",
  pch = 19,
  xlab = "Number of clusters k",
  ylab = "Average silhoutte width"
)
abline(
  v = which.max(sil),
  lty = 2
)

```
```{r}

cat("Average silhouette width optimal number of clusters:", which.max(sil), "\n")

```

## Calinsky criterion

The Calinski-Harabasz index is based on the intra and inter cluster sum of squares. So we are looking to maximize the index to find well separated clusters. To do this we repeatedly cluster the data then look how the genes partition themselves with increasing K:

```{r Calinsky criterion}

library(vegan)
fit <- cascadeKM(
  scaleData,
  1,
  20,
  iter = 100
)
plot(
  fit,
  sortg = T,
  grpmts.plot = T
)


```

```{r}

calinsky.best <- as.numeric(which.max(fit$results[2, ]))
cat("Calinsky criterion optimal number of clusters:", calinsky.best, "\n")

```

## Gap statistic

Next up is the gap statistic. The gap statistic comapres the log within-cluster sum of squares (discussed above) with it’s expectation under the null reference distribution. Then it chooses the cluster where the **gap** between the log(wss) and the maximim of the null ref is the largest:
```{r gap statistic}

library(cluster)
set.seed(13)
gap <- clusGap(
  scaleData,
  kmeans,
  20,
  B = 100,
  verbose = interactive()
)

```


```{r}

plot(
  gap,
  main = "Gap statistic"
)
abline(
  v = which.max(gap$Tab[ , 3]),
  lty = 2
)
```


## Affinity propagation

This is a newer method of clustering that I must admit is a bit over my head. It uses representatives from the data called ‘exemplars’ to build the clusters in a way thats similar to partitioning around medoids. It doesn’t require designating a cluster number. You can read more here.

```{r aff prop}

library(apcluster)
d.apclus <- apcluster(
  negDistMat(r = 2),
  scaleData
)
cat("affinity propagation optimal number of clusters:", length(d.apclus@clusters), "\n")

```

```{r}

# uncomment the next line for the heatmap:
heatmap(d.apclus,cexRow=0, cexCol=0)

```


## Hierarchical Clustering
It’s possible to use hierarchical clustering to provide insight into the optimum number of K clusters. The easiest way to do this is to perform the clustering then plot a heatmap and look for the clusters ‘by eye’.

First the matrix:

```{r}

# make the matrix
dist <- cor(t(scaleData), method = "pearson")
# make the tree
hr <- hclust(
  as.dist(1 - dist),
  method = "complete"
)

```


```{r}

# draw the heatmap
pheatmap(
  dist,
  cluster_rows = hr,
  cluster_cols = hr,
  scale = "row",
  show_rownames = F,
  show_colnames = F,
  color = viridis::viridis(100)
)

```


# Clustering the data

Let's perform the actual clustering with K = 4:

```{r clustering}

set.seed(42)
kClust <- kmeans(
  scaleData,
  centers = 4,
  nstart = 1000,
  iter.max = 100,
  algorithm = "Lloyd"
)
kClusters <- kClust$cluster


```

Calculate cluster cores aka "medoids"
```{r}

clust.centroid <- function(i, dat, clusters) {
  ind = (clusters == i)
  colMeans(dat[ind, ])
}

kClustCentroids <- sapply(
  levels(
    factor(
      kClusters
    )
  ),
  clust.centroid,
  scaleData,
  kClusters
)

```

Plotting the centroids to see how they behave:
```{r}

KMolten <- reshape2::melt(kClustCentroids)
colnames(KMolten) <- c("sample", "cluster", "value")

# plot
ggplot(
  KMolten,
  aes(x = sample, y = value, group = cluster, color = as.factor(cluster))
) +
  geom_point() +
  geom_line() +
  xlab("Tissue") +
  ylab("Expression") +
  labs(
    title = "Cluster Expression by tissue",
    color = "Cluster"
  ) +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
  )

```

```{r}

cor(kClustCentroids)


```

## Using cluster score to identify core genes

Calculating a membership score for clusters can help identify the core genes whose expression closely match the core. These genes might play a role in determining the expression of the cluster as a whole. These scores can also be used to a posteriori filter your genes if you want to drop genes that don’t fit well into any cluster.

To calculate the scores for a single cluster, in this case 2 we’ll extract the core data for cluster 2, then subset the scaled data by cluster =2. Then, we’ll calculate the ‘score’ by correlating each gene with the cluster core. We can then plot the results for each gene with the core overlayed:
```{r}

core2 <- KMolten[KMolten$cluster == "1", ]

# get cluster 2
K2 <- (scaleData[kClusters == "1", ]) 
# calculate correlatin with the core
corscore <- function(x){cor(x, core2$value)}
score <- apply(K2, 1, corscore)
# get the dataframe into long format for plotting
K2molten <- reshape2::melt(K2)
colnames(K2molten) <- c("gene", "sample", "value")
# add the score
K2molten <- merge(K2molten, score, by.x = "gene", by.y = "row.names", all.x = T)
colnames(K2molten) <- c("gene", "sample", "value", "score")
# order dataframe by score 
# to do this first create an ordering factor
K2molten$order_factor <- 1:length(K2molten$gene)
#order the dataframe by score
K2molten <- K2molten[order(K2molten$score), ]
# set the order by setting the factors
K2molten$order_factor <- factor(
  K2molten$order_factor, 
  levels = K2molten$order_factor
)

# Everything on the same plot
ggplot(K2molten, aes(x=sample,y=value)) + 
  geom_line(aes(colour=score, group=gene)) +
  scale_colour_gradientn(colours=c('blue1','red2')) +
  #this adds the core 
  geom_line(data=core2, aes(sample,value, group=cluster), color="black",inherit.aes=FALSE) +
  xlab("Time") +
  ylab("Expression") +
  labs(title= "Cluster 2 Expression by Time",color = "Score")

```


```{r}

# add vectors for traits
metaData <- metaData %>% 
  mutate(
    BA = case_when(tissue == "BA" ~ 1,
                   TRUE ~ 0),
    BD = case_when(
      tissue == "BD" ~ 1,
      TRUE ~ 0
    ),
    BP = case_when(
      tissue == "BP" ~ 1,
      TRUE ~ 0
    ),
    CR = case_when(
      tissue == "CR" ~ 1,
      TRUE ~ 0
    ),
    SM = case_when(
      tissue == "SM" ~ 1,
      TRUE ~ 0
    ),
    SP = case_when(
      tissue == "SP" ~ 1,
      TRUE ~ 0
    )
  ) %>% 
  dplyr::select(
    -1, -2
  )
# correlate the cluster cores to traits:
moduleTraitCor <- cor(kClustCentroids, metaData, use = "p")
# Extract the gene/sample numbers
nGenes <- nrow(dat)
nSamples <- ncol(dat)

# p value calculation from WGCNA
corPvalueStudent <- function(cor, nSamples) {
  T <- sqrt(nSamples - 2) * cor/sqrt(1 - cor^2)
  2 * pt(abs(T), nSamples - 2, lower.tail = FALSE)
}
moduleTraitPvalue <- corPvalueStudent(
  moduleTraitCor,
  nSamples
)

# generate a text matrix of the correlation and pvalue
textMatrix <- paste(
  signif(moduleTraitCor, 2),
  "\n(",
  signif(moduleTraitPvalue, 1),
  ")",
  sep = ""
)
dim(textMatrix) <- dim(moduleTraitCor)

```


```{r}

pheatmap(
  moduleTraitCor,
  cluster_rows = F,
  cluster_cols = T,
  clustering_distance_cols = "correlation",
  clustering_method = "complete",
  scale = "none",
  display_numbers = textMatrix,
  
  
)

```


